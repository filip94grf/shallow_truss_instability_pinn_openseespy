{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a044faf3-6ce6-4c37-8e9b-d41fa70ad79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\filip\\AppData\\Local\\Temp\\ipykernel_25676\\1563313602.py:38: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "Ku = 0\n",
      "ks = 0.0\n",
      "tg = 0.47619047619047616\n",
      "angle = 25.463345061871614\n",
      "Epoch 0, Loss: 0.08321680873632431, Improvement!\n",
      "Epoch 500, Loss: 0.02797701396048069, Improvement!\n",
      "Epoch 1000, Loss: 0.010854500345885754, No improvement for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function UniquePtr.__del__ at 0x00000200B37EDB80>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\filip\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\", line 71, in __del__\n",
      "    obj = self._obj\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from scipy.optimize import root_scalar\n",
    "import os\n",
    "\n",
    "#Define number of cores to be employed for the execution\n",
    "num_cores = 8\n",
    "tf.config.threading.set_intra_op_parallelism_threads(num_cores)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(num_cores)\n",
    "\n",
    "num_cores = 8\n",
    "tf.config.threading.set_intra_op_parallelism_threads(num_cores)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(num_cores)\n",
    "\n",
    "\n",
    "#Freezing the model for reproduction\n",
    "seed_value = 2\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "#Define model parameters\n",
    "class PINN:\n",
    "    def __init__(self, num_inputs, layers, num_outputs, E1, E2, A1, A2, Llevo, Ldesno, h, Ks):\n",
    "        self.model = self.build_model(num_inputs, layers, num_outputs)\n",
    "        self.E1 = E1\n",
    "        self.E2 = E2\n",
    "        self.A1 = A1\n",
    "        self.A2 = A2\n",
    "        self.Llevo = Llevo\n",
    "        self.Ldesno = Ldesno\n",
    "        self.h = h\n",
    "        self.Ks = Ks\n",
    "\n",
    "    def build_model(self, num_inputs, layers, num_outputs):\n",
    "        activation = 'tanh'\n",
    "        inputs = tf.keras.layers.Input(shape=(num_inputs,))\n",
    "        x = inputs\n",
    "        for layer in layers:\n",
    "            x = tf.keras.layers.Dense(layer, activation=activation, kernel_initializer='he_normal')(x)\n",
    "        outputs = tf.keras.layers.Dense(num_outputs, kernel_initializer='he_normal')(x)\n",
    "        return tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    def exact_solution(self, alphai, betai):\n",
    "        return 2*self.E2*self.A2*(np.tan(alphai)/(np.tan(betai)+np.tan(alphai))*np.cos(beta0)/np.cos(betai)-(self.Ldesno/(L)))*(np.cos(betai)*np.tan(alphai) + np.sin(betai)) - self.Ks*(self.h - ((L)*np.tan(betai)*np.tan(alphai))/(np.tan(betai) + np.tan(alphai)))\n",
    "\n",
    "    def loss(self, x, y_true):\n",
    "        y_pred = self.model(x)\n",
    "        return tf.reduce_mean(tf.square((y_true - y_pred)/total_samples))\n",
    "\n",
    "    def train(self, x_train, y_train, epochs, optimizer):\n",
    "        best_loss = np.inf\n",
    "        patience = 30  \n",
    "        patience_counter = 0 \n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            with tf.GradientTape() as tape:\n",
    "                loss_value = self.loss(x_train, y_train)\n",
    "            grads = tape.gradient(loss_value, self.model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "\n",
    "            if loss_value < best_loss:\n",
    "                best_loss = loss_value\n",
    "                patience_counter = 0\n",
    "                if epoch % 500 == 0:\n",
    "                    print(f\"Epoch {epoch}, Loss: {loss_value.numpy()}, Improvement!\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if epoch % 500 == 0:\n",
    "                    print(f\"Epoch {epoch}, Loss: {loss_value.numpy()}, No improvement for {patience_counter} epochs.\")\n",
    "    \n",
    "    #Updating parameters for new data\n",
    "    def update_parameters(self, E1, E2, A1, A2, Llevo, Ldesno, h, Ks):\n",
    "        #Physical parameters\n",
    "        self.E1 = E1\n",
    "        self.E2 = E2\n",
    "        self.A1 = A1\n",
    "        self.A2 = A2\n",
    "        self.Llevo = Llevo\n",
    "        self.Ldesno = Ldesno\n",
    "        self.h = h\n",
    "        self.Ks = Ks\n",
    "\n",
    "    def predict(self, x_new1, x_new2):\n",
    "        return self.loss(x_test, self.model.predict(x_new1, x_new2))\n",
    "\n",
    "    def train_loss(self, x_train, y_train):\n",
    "        train_loss_value = self.loss(x_train, y_train)\n",
    "        return train_loss_value\n",
    "\n",
    "    def test_loss(self, x_test, y_test):\n",
    "        test_loss_value = self.loss(x_test, y_test)\n",
    "        return test_loss_value\n",
    "\n",
    "    def all_loss(self, x_all, y_all):\n",
    "        all_loss_value = self.loss(x_all, y_all)\n",
    "        return all_loss_value\n",
    "\n",
    "#Network parameters\n",
    "num_inputs = 2  \n",
    "layers = [60, 60, 60] \n",
    "num_outputs = 1\n",
    "\n",
    "#Number of samples\n",
    "num_train_samples = 8000\n",
    "num_test_samples = 2000\n",
    "total_samples = num_train_samples + num_test_samples\n",
    "\n",
    "#Input values\n",
    "E1, E2, A1, A2, Llevo, Ldesno, h, Ks = 80000, 80000, 0.01, 0.01, 2.1, 2.1, 1, 0\n",
    "L=Llevo + Ldesno\n",
    "dlevo = math.sqrt(Llevo**2+h**2)\n",
    "ddesno = math.sqrt(Ldesno**2+h**2)\n",
    "alpha0 = math.asin(h/dlevo)\n",
    "beta0 = math.asin(h/ddesno)\n",
    "\n",
    "#Spring stiffness\n",
    "Ku = 0 #Nondimensional stiffness\n",
    "ks = Ku*((E1*A1+E2*A2)/2)*(math.sin(alpha0)**3)/h\n",
    "print(\"Ku =\", Ku)\n",
    "print(\"ks =\", ks)\n",
    "\n",
    "#Alpha and beta angles\n",
    "tg = h / Llevo\n",
    "atg = math.atan(tg)\n",
    "print(\"tg =\", tg)\n",
    "print(\"angle =\", np.rad2deg(atg))\n",
    "#Case E1!=E2\n",
    "if E1!=E2:\n",
    "    if tg <= 0.100:   #0-5 degree\n",
    "        alphai = 0.3 * np.random.uniform(-1, 1, total_samples)\n",
    "    elif tg <= 0.200: #5-10 degree\n",
    "        alphai = 0.5 * np.random.uniform(-1, 1, total_samples)\n",
    "    elif tg <= 0.300: #10-15 degree\n",
    "        alphai = 0.6 * np.random.uniform(-1, 1, total_samples)\n",
    "    elif tg <= 0.400: #15-20 degree\n",
    "        alphai = 0.7 * np.random.uniform(-1, 1, total_samples)\n",
    "    elif tg <= 0.465: #20-25 degree\n",
    "        alphai = 0.9 * np.random.uniform(-1, 1, total_samples)\n",
    "    else:             #25-30 degree\n",
    "        alphai = 1.0 * np.random.uniform(-1, 1, total_samples)\n",
    "\n",
    "#Case E1==E2\n",
    "else:\n",
    "    if tg <= 0.100:   #0-5 degree\n",
    "        alphai = 0.3 * np.random.uniform(-1, 1, total_samples)\n",
    "    elif tg <= 0.200: #5-10 degree\n",
    "        alphai = 0.5 * np.random.uniform(-1, 1, total_samples)\n",
    "    elif tg <= 0.300: #10-15 degree\n",
    "        alphai = 0.6 * np.random.uniform(-1, 1, total_samples)\n",
    "    elif tg <= 0.400: #15-20 degree\n",
    "        alphai = 0.7 * np.random.uniform(-1, 1, total_samples)\n",
    "    elif tg <= 0.465: #20-25 degree\n",
    "        alphai = 0.9 * np.random.uniform(-1, 1, total_samples)\n",
    "    else:             #25-30 degree\n",
    "        alphai = 1.0 * np.random.uniform(-1, 1, total_samples)\n",
    "\n",
    "#Betai angles calculation\n",
    "def func(x, alphai):\n",
    "    return (np.cos(x)/np.cos(alphai)) * (2*L*math.tan(alphai)/(math.tan(x)+math.tan(alphai))*math.cos(alpha0)/(L*math.cos(x))-1) - (E1*A1/(E2*A2)) * (2*(L-L*math.tan(alphai)/(math.tan(x)+math.tan(alphai)))*math.cos(alpha0)/(L*math.cos(alphai))-1)\n",
    "\n",
    "results = []\n",
    "for alphai in alphai:\n",
    "\n",
    "    current_func = lambda x: func(x, alphai)\n",
    "\n",
    "    bracket = [0, 1] if alphai >= 0 else [-1, 0]\n",
    "\n",
    "    try:\n",
    "        sol = root_scalar(current_func, bracket=bracket, method='brentq')\n",
    "        results.append((alphai, sol.root))\n",
    "    except ValueError:\n",
    "        results.append((alphai, 'No root found', None, False))\n",
    "\n",
    "df_results = pd.DataFrame(results, columns=['Alphai', 'Root'])\n",
    "\n",
    "\n",
    "df_results.to_excel(\"Root_Values.xlsx\", index=False)\n",
    "\n",
    "alphai = df_results['Alphai'].values\n",
    "betai = df_results['Root'].values\n",
    "\n",
    "#PINN model\n",
    "pinn = PINN(num_inputs, layers, num_outputs, E1, E2, A1, A2, Llevo, Ldesno, h, Ks)\n",
    "\n",
    "#Data split\n",
    "x_train_1 = alphai[:num_train_samples].reshape(-1, 1)\n",
    "x_train_2 = betai[:num_train_samples].reshape(-1, 1)\n",
    "x_test_1 = alphai[num_train_samples:].reshape(-1, 1)\n",
    "x_test_2 = betai[num_train_samples:].reshape(-1, 1)\n",
    "x_all_1 = alphai.reshape(-1, 1)\n",
    "x_all_2 = betai.reshape(-1, 1)\n",
    "\n",
    "#Train/Test set input\n",
    "x_train = np.column_stack((x_train_1, x_train_2))\n",
    "x_test = np.column_stack((x_test_1, x_test_2))\n",
    "x_all = np.column_stack((x_all_1, x_all_2))\n",
    "\n",
    "#Train/Test set output\n",
    "y_train = np.array([pinn.exact_solution(v1, v2) for v1, v2 in zip(x_train_1, x_train_2)])\n",
    "y_test = np.array([pinn.exact_solution(v3, v4) for v3, v4 in zip(x_test_1, x_test_2)])\n",
    "\n",
    "#Training time\n",
    "start = time.time()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1) \n",
    "pinn.train(x_train, y_train, epochs=3000, optimizer=optimizer) \n",
    "\n",
    "end = time.time()\n",
    "running_time = (end - start)\n",
    "print('Running Time: ', running_time, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d518e-b493-49b5-b866-d91701b9ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train output\n",
    "y_train = pinn.exact_solution(x_train[:, 0], x_train[:, 1])\n",
    "\n",
    "#Train loss\n",
    "train_loss = pinn.train_loss(x_train, y_train)\n",
    "\n",
    "#Print train loss\n",
    "print(f\"Train Loss: {train_loss.numpy()}\")\n",
    "\n",
    "#Test output\n",
    "y_test = pinn.exact_solution(x_test[:, 0], x_test[:, 1])\n",
    "\n",
    "#Test loss\n",
    "test_loss = pinn.test_loss(x_test, y_test)\n",
    "\n",
    "#Print test loss\n",
    "print(f\"Test Loss: {test_loss.numpy()}\")\n",
    "\n",
    "#All output\n",
    "y_all = pinn.exact_solution(x_all[:, 0], x_all[:, 1])\n",
    "\n",
    "#All loss\n",
    "all_loss = pinn.all_loss(x_all, y_all)\n",
    "\n",
    "#Print all loss\n",
    "print(f\"All Loss: {all_loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000371a4-d84b-499a-91ca-1192cdf78a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERTICAL/HORIZONTAL DISPLACEMENT VS FORCE + CRITICAL POINTS\n",
    "x_plot = np.linspace(0, -2.5, total_samples).reshape(-1, 1)\n",
    "alphai = np.linspace(alpha0, -1.5*alpha0, total_samples)\n",
    "\n",
    "#Betai angles\n",
    "def func(x, alphai):\n",
    "    return (np.cos(x)/np.cos(alphai)) * (2*L*math.tan(alphai)/(math.tan(x)+math.tan(alphai))*math.cos(alpha0)/(L*math.cos(x))-1) - (E1*A1/(E2*A2)) * (2*(L-L*math.tan(alphai)/(math.tan(x)+math.tan(alphai)))*math.cos(alpha0)/(L*math.cos(alphai))-1)\n",
    "\n",
    "results = []\n",
    "for alphai in alphai:\n",
    "    \n",
    "    current_func = lambda x: func(x, alphai)\n",
    "    \n",
    "    bracket = [0, 1] if alphai >= 0 else [-1, 0]\n",
    "    \n",
    "    try:\n",
    "        sol = root_scalar(current_func, bracket=bracket, method='brentq')\n",
    "        results.append((alphai, sol.root)) #,sol.iterations, sol.converged))\n",
    "    except ValueError:\n",
    "        results.append((alphai, 'No root found', None, False))\n",
    "        \n",
    "df_results = pd.DataFrame(results, columns=['Alphai', 'Betai'])\n",
    "\n",
    "\n",
    "df_results.to_excel(\"Root_Values.xlsx\", index=False)\n",
    "\n",
    "angle_za_exact_alpha = df_results['Alphai'].values\n",
    "angle_za_exact_beta = df_results['Betai'].values\n",
    "\n",
    "def find_critical_points_exact(y):\n",
    "    dy = np.diff(y)\n",
    "    critical_points_exact = np.where(np.diff(np.sign(dy)))[0]\n",
    "    return critical_points_exact + 1\n",
    "\n",
    "#EXACT SOLUTION\n",
    "y_exact = pinn.exact_solution(angle_za_exact_alpha, angle_za_exact_beta)\n",
    "\n",
    "critical_points_indices_exact = find_critical_points_exact(y_exact)\n",
    "x_coord_exact = x_plot[critical_points_indices_exact]\n",
    "y_coord_exact = y_exact[critical_points_indices_exact]\n",
    "\n",
    "#PINN SOLUTION\n",
    "predictive_set = np.column_stack((angle_za_exact_alpha, angle_za_exact_beta))\n",
    "y_pred = pinn.model.predict(predictive_set)\n",
    "y_pred = y_pred.flatten()\n",
    "\n",
    "#CRITICAL POINTS\n",
    "def find_growing_dropping_points(y):\n",
    "    dy = np.diff(y)\n",
    "    critical_indices = np.where(np.diff(np.sign(dy)))[0]  \n",
    "    adjusted_indices = critical_indices + 1  \n",
    "\n",
    "    growing_points = []\n",
    "    dropping_points = []\n",
    "\n",
    "    for i in adjusted_indices:\n",
    "        if i == 0 or i == len(y) - 1:\n",
    "            continue \n",
    "        if dy[i - 1] > 0 and dy[i] < 0:\n",
    "            dropping_points.append(i)\n",
    "        elif dy[i - 1] < 0 and dy[i] > 0:\n",
    "            growing_points.append(i)\n",
    "    \n",
    "    return growing_points, dropping_points\n",
    "\n",
    "growing_points_indices, dropping_points_indices = find_growing_dropping_points(y_pred)\n",
    "x_growing_coord_pinn = x_plot[growing_points_indices]\n",
    "y_growing_coord_pinn = y_pred[growing_points_indices]\n",
    "x_dropping_coord_pinn = x_plot[dropping_points_indices]\n",
    "y_dropping_coord_pinn = y_pred[dropping_points_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(abs(x_plot), -y_exact, label='Exact (closed-form) - Vertical displacement', color='blue', linestyle='--')\n",
    "plt.plot(abs(x_plot), -y_pred, label='PINN - Vertical displacement', color='red', linestyle='-')\n",
    "\n",
    "#HORIZONTAL DISPLACEMENTS\n",
    "tan_alpha = np.tan(angle_za_exact_alpha)\n",
    "tan_beta = np.tan(angle_za_exact_beta)\n",
    "x = L * tan_alpha / (tan_beta + tan_alpha)\n",
    "x_pom = L/2-x\n",
    "\n",
    "x_pom_np = x_pom.to_numpy() if hasattr(x_pom, 'to_numpy') else x_pom\n",
    "y_exact_np = y_exact.to_numpy() if hasattr(y_exact, 'to_numpy') else y_exact\n",
    "y_pred_np = y_pred.to_numpy() if hasattr(y_pred, 'to_numpy') else y_pred\n",
    "\n",
    "#PLOT HORIZONTAL DISPLACEMENTS\n",
    "plt.plot(x_pom_np, -y_exact_np, label='Exact (closed-form) - Horizontal displacement', color='orange', linestyle='--')\n",
    "plt.plot(x_pom_np, -y_pred_np, label='PINN - Horizontal displacement', color='green', linestyle='-')\n",
    "\n",
    "#Plot critical points - EXACT\n",
    "plt.scatter(abs(x_coord_exact), -y_coord_exact, color='black', zorder=5, label='Critical points - Exact (closed-form)')\n",
    "\n",
    "#Plot second critical point - PINN\n",
    "if len(x_growing_coord_pinn) > 0 and len(y_growing_coord_pinn) > 0: \n",
    "    plt.scatter(abs(x_growing_coord_pinn[-1]), -y_growing_coord_pinn[-1], color='green', zorder=5, label='Critical points - PINN')\n",
    "\n",
    "#Plot first critical point - PINN\n",
    "if len(x_dropping_coord_pinn) > 0 and len(y_dropping_coord_pinn) > 0:  \n",
    "    plt.scatter(abs(x_dropping_coord_pinn[0]), -y_dropping_coord_pinn[0], color='green', zorder=5)\n",
    "    \n",
    "plt.xlabel('Top Node Displacement [m]')\n",
    "plt.ylabel('Vertical Load (P) [kN]')\n",
    "plt.title('Comparison of Predicted and Analytical Vertical Displacements')\n",
    "plt.legend()\n",
    "#plt.ylim(0, 25)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0de22-c146-4727-8220-12ea3601bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print critical points\n",
    "print(\"First critical point - Exact solution - Displacement\", abs(x_coord_exact[0]))\n",
    "print(\"First critical point - Exact solution - Force\", -y_coord_exact[0])\n",
    "print(\"Second critical point - Exact solution - Displacement\", abs(x_coord_exact[-1]))\n",
    "print(\"Second critical point - Exact solution - Force\", -y_coord_exact[-1])\n",
    "print(\"First critical point - PINN - Displacement\", abs(x_dropping_coord_pinn[0]))\n",
    "print(\"First critical point - PINN - Force\", -y_dropping_coord_pinn[0])\n",
    "print(\"Second critical point - PINN - Displacement\", abs(x_growing_coord_pinn[-1]))\n",
    "print(\"Second critical point - PINN - Force\", -y_growing_coord_pinn[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0063f7f-4ddc-470c-b23d-dff43ca79272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the results to Excel file\n",
    "x_plot = pd.DataFrame(abs(x_plot))\n",
    "x_plot.to_excel(\"Shallow Truss VERTICAL DISPLACEMENT Ku=0.xlsx\")\n",
    "x_pom_np = pd.DataFrame(x_pom_np)\n",
    "x_pom_np.to_excel(\"Shallow Truss HORIZONTAL DISPLACEMENT Ku=0.xlsx\")\n",
    "\n",
    "y_exact = pd.DataFrame(-y_exact)\n",
    "y_exact.to_excel(\"Shallow Truss FORCE VERTICAL EXACT Ku=0.xlsx\")\n",
    "y_exact_np = pd.DataFrame(-y_exact_np)\n",
    "y_exact_np.to_excel(\"Shallow Truss FORCE HORIZONTAL EXACT Ku=0.xlsx\")\n",
    "\n",
    "y_pred = pd.DataFrame(-y_pred)\n",
    "y_pred.to_excel(\"Shallow Truss FORCE VERTICAL PINN Ku=0.xlsx\")\n",
    "y_pred_np = pd.DataFrame(-y_pred_np)\n",
    "y_pred_np.to_excel(\"Shallow Truss FORCE HORIZONTAL PINN Ku=0.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cda151-781a-48c1-a18c-e9d4059a4e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate spring stiffness\n",
    "Ku_02 = 0.2 #Nondimensional stiffness\n",
    "ks = Ku_02*((E1*A1+E2*A2)/2)*(math.sin(alpha0)**3)/h #Stiffness\n",
    "print(\"Ku_0.2 =\", Ku_02)\n",
    "print(\"ks_0.2 =\", ks)\n",
    "\n",
    "Ku_04 = 0.4 \n",
    "ks = Ku_04*((E1*A1+E2*A2)/2)*(math.sin(alpha0)**3)/h \n",
    "print(\"Ku_0.4 =\", Ku_04)\n",
    "print(\"ks_0.4 =\", ks)\n",
    "\n",
    "Ku_06 = 0.6 \n",
    "ks = Ku_06*((E1*A1+E2*A2)/2)*(math.sin(alpha0)**3)/h \n",
    "print(\"Ku_0.6 =\", Ku_06)\n",
    "print(\"ks_0.6 =\", ks)\n",
    "\n",
    "Ku_08 = 0.8 \n",
    "ks = Ku_08*((E1*A1+E2*A2)/2)*(math.sin(alpha0)**3)/h \n",
    "print(\"Ku_0.8 =\", Ku_08)\n",
    "print(\"ks_0.8 =\", ks)\n",
    "\n",
    "Ku_10 = 1.0 \n",
    "ks = Ku_10*((E1*A1+E2*A2)/2)*(math.sin(alpha0)**3)/h \n",
    "print(\"Ku_1.0 =\", Ku_10)\n",
    "print(\"ks_1.0 =\", ks)\n",
    "\n",
    "Ku_15 = 1.5 \n",
    "ks = Ku_15*((E1*A1+E2*A2)/2)*(math.sin(alpha0)**3)/h \n",
    "print(\"Ku_1.5 =\", Ku_15)\n",
    "print(\"ks_1.5 =\", ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef88d8a4-82af-41da-a763-3029a37e99df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
